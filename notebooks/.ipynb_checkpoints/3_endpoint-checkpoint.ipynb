{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Endpoint for Explanations\n", "\n", "In this notebook, we'll deploy the model explainer to a HTTP endpoint\n", "using Amazon SageMaker and visualize the explanations.\n", "\n", "You can bring also\n", "bring your own trained models to explain. See the customizing section for\n", "more details.\n", "\n", "**Note**: When running this notebook on SageMaker Studio, you should make\n", "sure the 'SageMaker JumpStart Data Science 1.0' image/kernel is used. You\n", "can run all cells or step through them one at a time.\n", "\n", "<p align=\"center\">\n", "  <img src=\"https://github.com/awslabs/sagemaker-explaining-credit-decisions/raw/master/docs/architecture_diagrams/stage_3.png\" width=\"1000px\">\n", "</p>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We then import a variety of packages that will be used throughout\n", "the notebook. One of the most important packages used throughout this\n", "solution is the Amazon SageMaker Python SDK (i.e. `import sagemaker`). We\n", "also import modules from our own custom package that can be found at\n", "`./package`."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from bokeh.plotting import output_notebook\n", "import boto3\n", "import sagemaker\n", "from pathlib import Path\n", "from sagemaker.sklearn import SKLearnModel\n", "import sys\n", "\n", "sys.path.insert(0, '../package')\n", "from package import config, utils, visuals\n", "from package.data import schemas"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Up next, we define the current folder, a sagemaker session and a\n", "sagemaker client (from `boto3`)."]}, {"cell_type": "code", "execution_count": null, "metadata": {"lines_to_next_cell": 1}, "outputs": [], "source": ["current_folder = utils.get_current_folder(globals())\n", "sagemaker_session = sagemaker.Session()\n", "sagemaker_client = boto3.client('sagemaker')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We define a couple of functions below to retrive the model data (i.e.\n", "`model.tar.gz`) from the most recent trained model (from the last stage)."]}, {"cell_type": "code", "execution_count": null, "metadata": {"lines_to_next_cell": 1}, "outputs": [], "source": ["def get_latest_training_job(name_contains):\n", "    paginator = sagemaker_client.get_paginator('list_training_jobs')\n", "    try:\n", "        for page in paginator.paginate(NameContains=name_contains, StatusEquals='Completed'):\n", "            training_jobs = page['TrainingJobSummaries']\n", "            if len(training_jobs):\n", "                return training_jobs[0]['TrainingJobName']\n", "    except:\n", "        raise ValueError(\"Couldn't find any completed training jobs with '{}' in name.\".format(name_contains))\n", "\n", "\n", "def get_model_data(training_job):\n", "    response = sagemaker_client.describe_training_job(TrainingJobName=training_job)\n", "    assert 'ModelArtifacts' in response, \"Couldn't find ModelArtifacts for training job.\"\n", "    return response['ModelArtifacts']['S3ModelArtifacts']"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["latest_training_job = get_latest_training_job(config.SOLUTION_PREFIX)\n", "print(\"latest training job: {}\".format(latest_training_job))\n", "model_data = get_model_data(latest_training_job)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Our model explainer endpoint will be named as per the `explainer_name`\n", "variable. AWS CloudFormation will delete this endpoint (and endpoint\n", "configuration) during stack deletion if the `endpoint_name` is kept as\n", "is. You will need to manually delete the endpoint (and endpoint\n", "configuration) after stack deletion if you change this."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["explainer_name = \"{}-explainer\".format(config.SOLUTION_PREFIX)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We define the model to deploy which includes the explainer logic."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model = SKLearnModel(\n", "    name=explainer_name,\n", "    model_data=model_data,\n", "    role=config.IAM_ROLE,\n", "    entry_point='entry_point.py',\n", "    source_dir=str(Path(current_folder, '../containers/model/src').resolve()),\n", "    dependencies=[str(Path(current_folder, '../package/package').resolve())],\n", "    image_uri=config.ECR_IMAGE,\n", "    code_location='s3://' + str(Path(config.S3_BUCKET, config.OUTPUTS_S3_PREFIX))\n", ")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Calling `deploy` will start a container to host the model.\n", "You can expect this step to take approximately 5 minutes."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sagemaker.serializers import JSONSerializer\n", "from sagemaker.deserializers import JSONDeserializer\n", "\n", "entities = [\n", "    'data',\n", "    'features',\n", "    'descriptions',\n", "    'prediction',\n", "    'explanation_shap_values',\n", "    'explanation_shap_interaction_values'\n", "]\n", "\n", "explainer = model.deploy(\n", "    endpoint_name=explainer_name,\n", "    instance_type='ml.c5.xlarge',\n", "    initial_instance_count=1,\n", "    serializer=JSONSerializer(content_type=\"application/json; entities={}\".format(\",\".join(entities))),\n", "    deserializer=JSONDeserializer(),\n", "    tags=[{'Key': config.TAG_KEY, 'Value': config.SOLUTION_PREFIX}]\n", ")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["When you're trying to update the model for development purposes, but\n", "experiencing issues because the model/endpoint-config/endpoint already\n", "exists, you can delete the existing model/endpoint-config/endpoint by\n", "uncommenting and running the following commands:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# sagemaker_client.delete_endpoint(EndpointName=explainer_name)\n", "# sagemaker_client.delete_endpoint_config(EndpointConfigName=explainer_name)\n", "# sagemaker_client.delete_model(ModelName=explainer_name)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["When calling our new endpoint from the notebook, we use a Amazon\n", "SageMaker SDK\n", "[`Predictor`](https://sagemaker.readthedocs.io/en/stable/predictors.html).\n", "A `Predictor` is used to send data to an endpoint (as part of a request),\n", "and interpret the response. Creating a `Predictor` does not affect the\n", "actual endpoint. Our endpoint expects to receive (and also sends) JSON\n", "formatted objects, and uses `content_type` to specify the entities\n", "requested (e.g. prediction, features, explanation_shap_values, etc.), so\n", "we create a custom `Predictor` called `Explainer`. JSON is used because\n", "it is a standard endpoint format and the endpoint response contains a\n", "nested data structure."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Model Explanations\n", "We can demonstrate the output of our new `explainer` endpoint with an\n", "example. One option would be to take a sample from our test set, but\n", "let's construct a sample by hand. Our example credit application is for\n", "6000 EUR and will be put towards buying a used car. You can always come\n", "back later and make changes to certain values."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sample = {\n", "    'contact__has_telephone': False,\n", "    'credit__amount': 6000,\n", "    'credit__coapplicant': 1,\n", "    'credit__duration': 36,\n", "    'credit__guarantor': 0,\n", "    'credit__installment_rate': 3,\n", "    'credit__purpose': 'used_car',\n", "    'employment__duration': 0,\n", "    'employment__permit': 'foreign',\n", "    'employment__type': 'professional',\n", "    'finance__accounts__checking__balance': 'no_account',\n", "    'finance__accounts__savings__balance': 'low',\n", "    'finance__credits__other_banks': 0,\n", "    'finance__credits__other_stores': 0,\n", "    'finance__credits__this_bank': 1,\n", "    'finance__other_assets': 'life_insurance',\n", "    'finance__repayment_history': 'good',\n", "    'personal__num_dependents': 1,\n", "    'residence__duration': 4,\n", "    'residence__type': 'own'\n", "}"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We can call `explainer.predict` with features (for a credit application)\n", "to obtain a prediction and its associated explanation. Using `Explainer`,\n", "the features will be converted from a Python list into a JSON string\n", "(using the Amazon SageMaker Python SDK's in-built `json_serializer`).\n", "Additionally, it will notify to the endpoint that the contents being sent\n", "are JSON formatted and the explanation entities are required (via\n", "`content_type`), and a JSON formatted response is requested in return\n", "(via `accept`). And lastly, the JSON response is converted back into\n", "Python objects (using `json_deserializer`).\n", "\n", "**Caution**: the probability returned by this model has not been\n", "calibrated. When the model gives a probability of credit default of 20%,\n", "for example, this does not necessarily mean that 20% of applications with\n", "a probability of 20% resulted in credit default. Calibration is a useful\n", "property in certain circumstances, but is not required in cases where\n", "discrimination between cases of default and non-defult is sufficient.\n", "[CalibratedClassifierCV](https://scikit-learn.org/stable/modules/generated/sklearn.calibration.CalibratedClassifierCV.html)\n", "from\n", "[Scikit-learn](https://scikit-learn.org/stable/modules/calibration.html)\n", "can be used to calibrate a model. Calibration also has an impact on the\n", "explanations. Since the calibration process is typically non-linear, it\n", "breaks the additive property of Shapley Values.\n", "[`KernelExplainer`](https://shap.readthedocs.io/en/latest/) can handle\n", "this case, but is typically much slower to compute the explanations."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["output = explainer.predict(sample)\n", "prediction = output['prediction']\n", "print(\"Credit default risk: {:.2%}\".format(prediction))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Visualizing Explanations\n", "Although `output` contains all the information required to explain\n", "the machine learning model's prediction, looking at long lists of numbers\n", "isn't especially helpful. We provide a number of visualization that\n", "clearly show which features increase and decrease the risk of credit\n", "default for an individual credit application.\n", "\n", "A waterfall chart can be used to show the cumulative effect of each\n", "feature. Starting with the baseline probability for credit defaults (at\n", "the bottom of the chart), we can see how each additional feature shifts\n", "the probability. Green arrows indicate that the feature <span\n", "style=\"color:#69AE35\">*decreased* the predicted credit default\n", "risk</span> for the individual credit application. While red arrows\n", "indicate that the feature <span style=\"color:#FF5733\">*increased* the\n", "predicted credit default risk</span> for the individual credit\n", "application. After all features have been considered, we reach the final\n", "predicted credit default risk (at the top of the chart).\n", "\n", "We're using [`bokeh`](https://docs.bokeh.org/en/latest/index.html#) for\n", "interactive charts, so let's start by calling `output_notebook` to show the\n", "plots inside the notebook."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["output_notebook()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Summary Explanation\n", "As mentioned earlier on in this notebook, our features can be grouped\n", "together into categories. We can extract the top level category for each\n", "feature, by extracting the start of the feature name before the level\n", "seperator. We use two consecutive underscores (`__`) as our level\n", "separator. Once we have the category for each feature, we can calculate\n", "the the overall effect for each category. All of this is performed in\n", "`summarize_explanation`."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["explanation_summary = visuals.summary_explanation(output)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We then show the associated waterfall chart."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["x_axis_label = 'Credit Default Risk Score (%)'\n", "summary_waterfall = visuals.WaterfallChart(\n", "    baseline=explanation_summary['expected_value'],\n", "    shap_values=explanation_summary['shap_values'],\n", "    names=explanation_summary['feature_names'],\n", "    descriptions=explanation_summary['feature_descriptions'],\n", "    max_features=10,\n", "    x_axis_label=x_axis_label,\n", ")\n", "summary_waterfall.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We can see from the summary waterfall chart above that features related\n", "to finance have the largest combined effect on the credit default risk.\n", "Although features realted to finance reduce the credit default risk, the\n", "features related to employment bring the risk back up again to a certain\n", "degree."]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Detailed Explanation\n", "After examining the high level explanation, we can drill down into the\n", "individual features that contribute to the credit default risk score."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["explanation = visuals.detailed_explanation(output)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["detailed_waterfall = visuals.WaterfallChart(\n", "    baseline=explanation['expected_value'],\n", "    shap_values=explanation['shap_values'],\n", "    names=explanation['feature_names'],\n", "    feature_values=explanation['feature_values'],\n", "    descriptions=explanation['feature_descriptions'],\n", "    max_features=10,\n", "    x_axis_label=x_axis_label\n", ")\n", "detailed_waterfall.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We can see from the detailed waterfall chart above that not having a\n", "checking account with the same bank indicates a lower credit default\n", "risk. Since this is an influential feature for the model but the reason\n", "for this effect is not obvious, it may warrant further investigation. We\n", "can also see that using the credit to purchase a used car is associated\n", "with a lower credit default risk too. After this we see a number of\n", "features that increase the credit default risk: a credit amount of 6000\n", "EUR, a lack of employment and a credit duration of 36 months. Another\n", "potential area for investigation, would be related to the repayment\n", "history feature. We can see that *not* having a very poor repayment\n", "history is associated with a higher credit default risk score. We may\n", "have artifacts in the datasets that caused the model to use this feature\n", "in such an unintuitive way."]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Counterfactual Example\n", "And lastly, we switch the value of the checking account balance of the\n", "applicant from `no_account` to `negative`. We can then see how the\n", "overall prediction of the model changes, and also see the updated\n", "contribution of this feature. Clearly, this application has become\n", "substantially more risky."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["counter_sample = dict(sample)\n", "counter_sample['finance__accounts__checking__balance'] = 'negative'  # from 'no_account'\n", "counter_output = explainer.predict(counter_sample)\n", "counter_explanation = visuals.detailed_explanation(counter_output)\n", "visuals.WaterfallChart(\n", "    baseline=counter_explanation['expected_value'],\n", "    shap_values=counter_explanation['shap_values'],\n", "    names=counter_explanation['feature_names'],\n", "    feature_values=counter_explanation['feature_values'],\n", "    descriptions=counter_explanation['feature_descriptions'],\n", "    max_features=10,\n", "    x_axis_label=x_axis_label,\n", ").show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Clean Up\n", "\n", "When you've finished with the explainer endpoint (and associated\n", "endpoint-config), make sure that you delete it to avoid accidental\n", "charges."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# sagemaker_client.delete_endpoint(EndpointName=explainer_name)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Next Stage\n", "\n", "Up next we'll use Amazon SageMaker Batch Transform to obtain explanations\n", "for our complete dataset.\n", "\n", "[Click here to continue.](./4_batch_transform.ipynb)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}], "metadata": {"jupytext": {"cell_metadata_filter": "-all", "main_language": "python", "notebook_metadata_filter": "-all"}, "kernelspec": {"display_name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:793310587911:image/sagemaker-jumpstart-data-science-1.0", "language": "python", "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:793310587911:image/sagemaker-jumpstart-data-science-1.0"}}, "nbformat": 4, "nbformat_minor": 4}