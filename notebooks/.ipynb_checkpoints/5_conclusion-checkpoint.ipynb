{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Conclusion\n", "\n", "We've covered a lot in this solution. We started by preparing our dataset\n", "using AWS Glue. We then trained a LightGBM model using Amazon SageMaker\n", "Training Jobs to give us an example model to explain. We then generated\n", "explanations in two different ways: firstly by using a real-time HTTP\n", "endpoint, and the using Batch Transform to compute explanations in batch.\n", "And we wrapped things up with a dashboard that visualized the\n", "explanations for individual predictions and in aggregate too.\n", "\n", "<p align=\"center\">\n", "  <img src=\"https://github.com/awslabs/sagemaker-explaining-credit-decisions/raw/master/docs/architecture_diagrams/complete.png\" width=\"1000px\">\n", "</p>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Clean Up\n", "\n", "When you've finished with this solution, make sure that you delete all\n", "unwanted AWS resources.\n", "\n", "AWS CloudFormation can be used to automatically delete all standard\n", "resources that have been created by the solution and notebooks.\n", "\n", "**Caution**: You need to manually delete any extra resources that you may\n", "have created in these notebooks. Some examples include, extra Amazon S3\n", "buckets (to the solution's default bucket), extra Amazon SageMaker\n", "endpoints (using a custom name), and extra Amazon ECR repositories.\n", "\n", "You can now return to AWS CloudFormation and delete the stack."]}], "metadata": {"jupytext": {"cell_metadata_filter": "-all", "main_language": "python", "notebook_metadata_filter": "-all"}, "kernelspec": {"display_name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:793310587911:image/sagemaker-jumpstart-data-science-1.0", "language": "python", "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:793310587911:image/sagemaker-jumpstart-data-science-1.0"}}, "nbformat": 4, "nbformat_minor": 4}